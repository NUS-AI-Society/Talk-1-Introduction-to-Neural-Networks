{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "335ef131-c082-4a42-b252-d62f23d4cc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "from numpy.typing import NDArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bee27793-196e-4458-a248-6ad8aaa558d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41996</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41997</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41998</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41999</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42000 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0          1       0       0       0       0       0       0       0       0   \n",
       "1          0       0       0       0       0       0       0       0       0   \n",
       "2          1       0       0       0       0       0       0       0       0   \n",
       "3          4       0       0       0       0       0       0       0       0   \n",
       "4          0       0       0       0       0       0       0       0       0   \n",
       "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "41995      0       0       0       0       0       0       0       0       0   \n",
       "41996      1       0       0       0       0       0       0       0       0   \n",
       "41997      7       0       0       0       0       0       0       0       0   \n",
       "41998      6       0       0       0       0       0       0       0       0   \n",
       "41999      9       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0           0  ...         0         0         0         0         0   \n",
       "1           0  ...         0         0         0         0         0   \n",
       "2           0  ...         0         0         0         0         0   \n",
       "3           0  ...         0         0         0         0         0   \n",
       "4           0  ...         0         0         0         0         0   \n",
       "...       ...  ...       ...       ...       ...       ...       ...   \n",
       "41995       0  ...         0         0         0         0         0   \n",
       "41996       0  ...         0         0         0         0         0   \n",
       "41997       0  ...         0         0         0         0         0   \n",
       "41998       0  ...         0         0         0         0         0   \n",
       "41999       0  ...         0         0         0         0         0   \n",
       "\n",
       "       pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0             0         0         0         0         0  \n",
       "1             0         0         0         0         0  \n",
       "2             0         0         0         0         0  \n",
       "3             0         0         0         0         0  \n",
       "4             0         0         0         0         0  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "41995         0         0         0         0         0  \n",
       "41996         0         0         0         0         0  \n",
       "41997         0         0         0         0         0  \n",
       "41998         0         0         0         0         0  \n",
       "41999         0         0         0         0         0  \n",
       "\n",
       "[42000 rows x 785 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/train.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7db1171-8cdd-45ee-921f-8e6e8bf4635b",
   "metadata": {},
   "source": [
    "# Explanation (from kaggle)\n",
    "The data files train.csv and test.csv contain gray-scale images of hand-drawn digits, from zero through nine.\n",
    "\n",
    "Each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255, inclusive.\n",
    "\n",
    "The training data set, (train.csv), has 785 columns. The first column, called \"label\", is the digit that was drawn by the user. The rest of the columns contain the pixel-values of the associated image.\n",
    "\n",
    "Each pixel column in the training set has a name like pixelx, where x is an integer between 0 and 783, inclusive. To locate this pixel on the image, suppose that we have decomposed x as x = i * 28 + j, where i and j are integers between 0 and 27, inclusive. Then pixelx is located on row i and column j of a 28 x 28 matrix, (indexing by zero).\n",
    "\n",
    "For example, pixel31 indicates the pixel that is in the fourth column from the left, and the second row from the top, as in the ascii-diagram below.\n",
    "\n",
    "Visually, if we omit the \"pixel\" prefix, the pixels make up the image like this:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "065ecc25-1627-4232-b5e0-2dc0093d3a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grid(dataframe):\n",
    "    # Select 9 random samples from the dataframe\n",
    "    sample_df = dataframe.sample(4, random_state=42)\n",
    "    \n",
    "    # Create a 3x3 subplot\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(8, 8))\n",
    "    \n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # Extract the pixel values and reshape into a 28x28 array\n",
    "        pixel_values = sample_df.iloc[i, 1:].values.reshape(28, 28)\n",
    "        \n",
    "        # Plot the image on the current subplot\n",
    "        ax.imshow(pixel_values, cmap='gray')\n",
    "        ax.set_title(f\"Label: {sample_df.iloc[i, 0]}\")\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def count_labels_percentage_sorted(dataframe):\n",
    "    label_percentages = dataframe['label'].value_counts(normalize=True) * 100\n",
    "    return label_percentages.sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7c95dff-0f48-4af5-9b24-302e5888074e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_grid(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e1791be-6f30-4d89-b753-9c26b3eed226",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0     9.838095\n",
      "1    11.152381\n",
      "2     9.945238\n",
      "3    10.359524\n",
      "4     9.695238\n",
      "5     9.035714\n",
      "6     9.850000\n",
      "7    10.478571\n",
      "8     9.673810\n",
      "9     9.971429\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "sorted_label_percentages = count_labels_percentage_sorted(df)\n",
    "print(sorted_label_percentages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74c6de36-ac58-478e-bcfb-74fc7e1423c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df.sample(frac=0.8, random_state=42)\n",
    "val_df = df.drop(train_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70e31ba2-5096-4a60-86f1-bbeaa836b0df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5457</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38509</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25536</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31803</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39863</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17290</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41320</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19502</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26867</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33600 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "5457       8       0       0       0       0       0       0       0       0   \n",
       "38509      1       0       0       0       0       0       0       0       0   \n",
       "25536      9       0       0       0       0       0       0       0       0   \n",
       "31803      9       0       0       0       0       0       0       0       0   \n",
       "39863      8       0       0       0       0       0       0       0       0   \n",
       "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "17290      6       0       0       0       0       0       0       0       0   \n",
       "41320      1       0       0       0       0       0       0       0       0   \n",
       "760        8       0       0       0       0       0       0       0       0   \n",
       "19502      5       0       0       0       0       0       0       0       0   \n",
       "26867      4       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "5457        0  ...         0         0         0         0         0   \n",
       "38509       0  ...         0         0         0         0         0   \n",
       "25536       0  ...         0         0         0         0         0   \n",
       "31803       0  ...         0         0         0         0         0   \n",
       "39863       0  ...         0         0         0         0         0   \n",
       "...       ...  ...       ...       ...       ...       ...       ...   \n",
       "17290       0  ...         0         0         0         0         0   \n",
       "41320       0  ...         0         0         0         0         0   \n",
       "760         0  ...         0         0         0         0         0   \n",
       "19502       0  ...         0         0         0         0         0   \n",
       "26867       0  ...         0         0         0         0         0   \n",
       "\n",
       "       pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "5457          0         0         0         0         0  \n",
       "38509         0         0         0         0         0  \n",
       "25536         0         0         0         0         0  \n",
       "31803         0         0         0         0         0  \n",
       "39863         0         0         0         0         0  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "17290         0         0         0         0         0  \n",
       "41320         0         0         0         0         0  \n",
       "760           0         0         0         0         0  \n",
       "19502         0         0         0         0         0  \n",
       "26867         0         0         0         0         0  \n",
       "\n",
       "[33600 rows x 785 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3ebf2d4-c977-417b-9ab3-88110c4f71f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0     9.922619\n",
      "1    11.202381\n",
      "2    10.059524\n",
      "3    10.395833\n",
      "4     9.699405\n",
      "5     8.997024\n",
      "6     9.785714\n",
      "7    10.333333\n",
      "8     9.681548\n",
      "9     9.922619\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(count_labels_percentage_sorted(train_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bafca795-f89d-4926-a0fb-eb80a8875006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0     9.500000\n",
      "1    10.952381\n",
      "2     9.488095\n",
      "3    10.214286\n",
      "4     9.678571\n",
      "5     9.190476\n",
      "6    10.107143\n",
      "7    11.059524\n",
      "8     9.642857\n",
      "9    10.166667\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(count_labels_percentage_sorted(val_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4275db8c-2138-48f6-850f-fe468a2661a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(\n",
    "    row: NDArray[np.float64], \n",
    "    W0: NDArray[np.float64], b0: NDArray[np.float64], \n",
    "    W1: NDArray[np.float64], b1: NDArray[np.float64],\n",
    "    W2: NDArray[np.float64], b2: NDArray[np.float64]\n",
    ") -> NDArray[np.float64]:\n",
    "\n",
    "    # Layer 0 (Input to Hidden Layer 1)\n",
    "    z0: NDArray[np.float64] = np.dot(row, W0) + b0  # Linear transformation\n",
    "    a0: NDArray[np.float64] = relu(z0)              # Apply ReLU activation\n",
    "\n",
    "    # Layer 1 (Hidden Layer 1 to Hidden Layer 2)\n",
    "    z1: NDArray[np.float64] = np.dot(a0, W1) + b1   # Linear transformation\n",
    "    a1: NDArray[np.float64] = relu(z1)              # Apply ReLU activation\n",
    "\n",
    "    # Layer 2 (Hidden Layer 2 to Output Layer)\n",
    "    z2: NDArray[np.float64] = np.dot(a1, W2) + b2   # Linear transformation\n",
    "    output: NDArray[np.float64] = softmax(z2)       # Apply softmax to get probabilities\n",
    "\n",
    "    return output\n",
    "\n",
    "def cross_entropy_loss(output: NDArray[np.float64], target: NDArray[np.float64]) -> float:\n",
    "    return -np.sum(target * np.log(output + 1e-9))  # Adding a small value to avoid log(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49cdfce0-106d-417f-9185-ce922d31e920",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def relu(x: NDArray[np.float64]) -> NDArray[np.float64]:\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def softmax(x: NDArray[np.float64]) -> NDArray[np.float64]:\n",
    "    exp_x = np.exp(x - np.max(x, axis=-1, keepdims=True))\n",
    "    return exp_x / np.sum(exp_x, axis=-1, keepdims=True)\n",
    "\n",
    "def cross_entropy_loss(output: NDArray[np.float64], target: NDArray[np.float64]) -> float:\n",
    "    return -np.sum(target * np.log(output + 1e-9))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c45a283-315a-42e2-904d-955d4a45eff2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09858591 0.10125714 0.10052527 0.09926226 0.10077043 0.10094543\n",
      " 0.10034162 0.09918815 0.0996525  0.09947129]\n"
     ]
    }
   ],
   "source": [
    "row: NDArray[np.float64] = df.iloc[0, 1:].values.astype(np.float64)\n",
    "\n",
    "input_size = 784  # Number of input neurons (28x28 pixels)\n",
    "hidden_layer_size = 10  # Number of neurons in the hidden layers\n",
    "output_size = 10  # Number of output neurons (for digits 0-9)\n",
    "\n",
    "\n",
    "# Random initialization of weights\n",
    "W0: NDArray[np.float64] = np.random.randn(input_size, hidden_layer_size) * 0.01\n",
    "W1: NDArray[np.float64] = np.random.randn(hidden_layer_size, hidden_layer_size) * 0.01\n",
    "W2: NDArray[np.float64] = np.random.randn(hidden_layer_size, output_size) * 0.01\n",
    "\n",
    "# Random initialization of biases\n",
    "b0: NDArray[np.float64] = np.random.randn(hidden_layer_size) * 0.01\n",
    "b1: NDArray[np.float64] = np.random.randn(hidden_layer_size) * 0.01\n",
    "b2: NDArray[np.float64] = np.random.randn(output_size) * 0.01\n",
    "output = forward_pass(row, W0, b0, W1, b1, W2, b2)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89e2c619-e4e0-44e4-b3fb-cdccbd604fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backpropagate(\n",
    "    row: NDArray[np.float64], \n",
    "    target: NDArray[np.float64],\n",
    "    W0: NDArray[np.float64], b0: NDArray[np.float64], \n",
    "    W1: NDArray[np.float64], b1: NDArray[np.float64],\n",
    "    W2: NDArray[np.float64], b2: NDArray[np.float64],\n",
    "    learning_rate: float\n",
    "):\n",
    "    # Forward pass\n",
    "    z0 = np.dot(row, W0) + b0\n",
    "    a0 = relu(z0)\n",
    "\n",
    "    z1 = np.dot(a0, W1) + b1\n",
    "    a1 = relu(z1)\n",
    "\n",
    "    z2 = np.dot(a1, W2) + b2\n",
    "    output = softmax(z2)\n",
    "\n",
    "    # Compute the loss (for reference)\n",
    "    loss = cross_entropy_loss(output, target)\n",
    "    print(f\"Loss: {loss}\")\n",
    "\n",
    "    # Backward pass\n",
    "\n",
    "    # Gradient of the loss with respect to the output\n",
    "    dL_dz2 = output - target  # Gradient of cross-entropy loss with respect to z2\n",
    "\n",
    "    # Gradients for W2 and b2\n",
    "    dL_dW2 = np.outer(a1, dL_dz2)  # (10, 10)\n",
    "    dL_db2 = dL_dz2  # (10,)\n",
    "\n",
    "    # Backpropagate through the second layer (ReLU)\n",
    "    dL_da1 = np.dot(W2, dL_dz2)  # (10,)\n",
    "    dL_dz1 = dL_da1 * (z1 > 0)  # Derivative of ReLU with respect to z1\n",
    "\n",
    "    # Gradients for W1 and b1\n",
    "    dL_dW1 = np.outer(a0, dL_dz1)  # (10, 10)\n",
    "    dL_db1 = dL_dz1  # (10,)\n",
    "\n",
    "    # Backpropagate through the first layer (ReLU)\n",
    "    dL_da0 = np.dot(W1, dL_dz1)  # (10,)\n",
    "    dL_dz0 = dL_da0 * (z0 > 0)  # Derivative of ReLU with respect to z0\n",
    "\n",
    "    # Gradients for W0 and b0\n",
    "    dL_dW0 = np.outer(row, dL_dz0)  # (784, 10)\n",
    "    dL_db0 = dL_dz0  # (10,)\n",
    "\n",
    "    # Update weights and biases using gradient descent\n",
    "    W2 -= learning_rate * dL_dW2\n",
    "    b2 -= learning_rate * dL_db2\n",
    "\n",
    "    W1 -= learning_rate * dL_dW1\n",
    "    b1 -= learning_rate * dL_db1\n",
    "\n",
    "    W0 -= learning_rate * dL_dW0\n",
    "    b0 -= learning_rate * dL_db0\n",
    "\n",
    "    return W0, b0, W1, b1, W2, b2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "240fde04-af7e-404c-8026-232130982011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.3065937583033636\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have the data\n",
    "row: NDArray[np.float64] = df.iloc[0, 1:].values.astype(np.float64)\n",
    "target = np.zeros(10)\n",
    "target[3] = 1  # Example target (e.g., digit '3')\n",
    "\n",
    "# Initialize weights and biases\n",
    "W0 = np.random.randn(784, 10) * 0.01\n",
    "b0 = np.random.randn(10) * 0.01\n",
    "\n",
    "W1 = np.random.randn(10, 10) * 0.01\n",
    "b1 = np.random.randn(10) * 0.01\n",
    "\n",
    "W2 = np.random.randn(10, 10) * 0.01\n",
    "b2 = np.random.randn(10) * 0.01\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Perform a single backpropagation step\n",
    "W0, b0, W1, b1, W2, b2 = backpropagate(row, target, W0, b0, W1, b1, W2, b2, learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480309d9-3c81-40ff-97e9-3098743fd546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 12755.0986, Train Acc: 0.8955, Val Loss: 3251.6918, Val Acc: 0.8951\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Tuple, List\n",
    "from numpy.typing import NDArray\n",
    "\n",
    "def relu(x: NDArray[np.float64]) -> NDArray[np.float64]:\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def softmax(x: NDArray[np.float64]) -> NDArray[np.float64]:\n",
    "    exp_x = np.exp(x - np.max(x, axis=-1, keepdims=True))\n",
    "    return exp_x / np.sum(exp_x, axis=-1, keepdims=True)\n",
    "\n",
    "def cross_entropy_loss(output: NDArray[np.float64], target: NDArray[np.float64]) -> float:\n",
    "    return -np.sum(target * np.log(output + 1e-9))\n",
    "\n",
    "def forward_pass(\n",
    "    X: NDArray[np.float64],\n",
    "    W0: NDArray[np.float64], b0: NDArray[np.float64],\n",
    "    W1: NDArray[np.float64], b1: NDArray[np.float64],\n",
    "    W2: NDArray[np.float64], b2: NDArray[np.float64]\n",
    ") -> Tuple[NDArray[np.float64], NDArray[np.float64], NDArray[np.float64], NDArray[np.float64], NDArray[np.float64], NDArray[np.float64]]:\n",
    "    z0 = np.dot(X, W0) + b0\n",
    "    a0 = relu(z0)\n",
    "    z1 = np.dot(a0, W1) + b1\n",
    "    a1 = relu(z1)\n",
    "    z2 = np.dot(a1, W2) + b2\n",
    "    output = softmax(z2)\n",
    "    return output, a1, z1, a0, z0, X\n",
    "\n",
    "def backpropagate(\n",
    "    output: NDArray[np.float64], target: NDArray[np.float64],\n",
    "    a1: NDArray[np.float64], z1: NDArray[np.float64],\n",
    "    a0: NDArray[np.float64], z0: NDArray[np.float64],\n",
    "    X: NDArray[np.float64],\n",
    "    W0: NDArray[np.float64], b0: NDArray[np.float64],\n",
    "    W1: NDArray[np.float64], b1: NDArray[np.float64],\n",
    "    W2: NDArray[np.float64], b2: NDArray[np.float64],\n",
    "    learning_rate: float\n",
    ") -> Tuple[NDArray[np.float64], NDArray[np.float64], NDArray[np.float64], NDArray[np.float64], NDArray[np.float64], NDArray[np.float64]]:\n",
    "    batch_size = output.shape[0]\n",
    "    \n",
    "    dL_dz2 = output - target\n",
    "    dL_dW2 = np.dot(a1.T, dL_dz2) / batch_size\n",
    "    dL_db2 = np.mean(dL_dz2, axis=0)\n",
    "\n",
    "    dL_da1 = np.dot(dL_dz2, W2.T)\n",
    "    dL_dz1 = dL_da1 * (z1 > 0)\n",
    "    dL_dW1 = np.dot(a0.T, dL_dz1) / batch_size\n",
    "    dL_db1 = np.mean(dL_dz1, axis=0)\n",
    "\n",
    "    dL_da0 = np.dot(dL_dz1, W1.T)\n",
    "    dL_dz0 = dL_da0 * (z0 > 0)\n",
    "    dL_dW0 = np.dot(X.T, dL_dz0) / batch_size\n",
    "    dL_db0 = np.mean(dL_dz0, axis=0)\n",
    "\n",
    "    # Gradient clipping\n",
    "    max_grad_norm = 1.0\n",
    "    for grad in [dL_dW2, dL_db2, dL_dW1, dL_db1, dL_dW0, dL_db0]:\n",
    "        np.clip(grad, -max_grad_norm, max_grad_norm, out=grad)\n",
    "\n",
    "    # Update weights and biases\n",
    "    W2 -= learning_rate * dL_dW2\n",
    "    b2 -= learning_rate * dL_db2\n",
    "    W1 -= learning_rate * dL_dW1\n",
    "    b1 -= learning_rate * dL_db1\n",
    "    W0 -= learning_rate * dL_dW0\n",
    "    b0 -= learning_rate * dL_db0\n",
    "\n",
    "    return W0, b0, W1, b1, W2, b2\n",
    "\n",
    "def train_model(\n",
    "    train_df: pd.DataFrame,\n",
    "    val_df: pd.DataFrame,\n",
    "    hidden_layer_size: int = 128,\n",
    "    batch_size: int = 32,\n",
    "    learning_rate: float = 0.01,\n",
    "    epochs: int = 10\n",
    ") -> Tuple[List[float], List[float], List[float], List[float]]:\n",
    "    input_size = 784\n",
    "    output_size = 10\n",
    "\n",
    "    # Initialize weights and biases\n",
    "    W0 = np.random.randn(input_size, hidden_layer_size) * np.sqrt(2. / input_size)\n",
    "    b0 = np.zeros(hidden_layer_size)\n",
    "    W1 = np.random.randn(hidden_layer_size, hidden_layer_size) * np.sqrt(2. / hidden_layer_size)\n",
    "    b1 = np.zeros(hidden_layer_size)\n",
    "    W2 = np.random.randn(hidden_layer_size, output_size) * np.sqrt(2. / hidden_layer_size)\n",
    "    b2 = np.zeros(output_size)\n",
    "\n",
    "    train_losses, train_accuracies = [], []\n",
    "    val_losses, val_accuracies = [], []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Shuffle the training data\n",
    "        train_df = train_df.sample(frac=1).reset_index(drop=True)\n",
    "        \n",
    "        # Mini-batch training\n",
    "        for start in range(0, len(train_df), batch_size):\n",
    "            end = start + batch_size\n",
    "            batch = train_df.iloc[start:end]\n",
    "            \n",
    "            X = batch.iloc[:, 1:].values.astype(np.float64) / 255.0\n",
    "            y = batch.iloc[:, 0].values.astype(int)\n",
    "            target = np.eye(10)[y]\n",
    "\n",
    "            output, a1, z1, a0, z0, X = forward_pass(X, W0, b0, W1, b1, W2, b2)\n",
    "            W0, b0, W1, b1, W2, b2 = backpropagate(output, target, a1, z1, a0, z0, X, W0, b0, W1, b1, W2, b2, learning_rate)\n",
    "\n",
    "        # Evaluate on training set\n",
    "        train_output, _, _, _, _, _ = forward_pass(train_df.iloc[:, 1:].values.astype(np.float64) / 255.0, W0, b0, W1, b1, W2, b2)\n",
    "        train_loss = cross_entropy_loss(train_output, np.eye(10)[train_df.iloc[:, 0].values.astype(int)])\n",
    "        train_accuracy = np.mean(np.argmax(train_output, axis=1) == train_df.iloc[:, 0].values)\n",
    "        \n",
    "        # Evaluate on validation set\n",
    "        val_output, _, _, _, _, _ = forward_pass(val_df.iloc[:, 1:].values.astype(np.float64) / 255.0, W0, b0, W1, b1, W2, b2)\n",
    "        val_loss = cross_entropy_loss(val_output, np.eye(10)[val_df.iloc[:, 0].values.astype(int)])\n",
    "        val_accuracy = np.mean(np.argmax(val_output, axis=1) == val_df.iloc[:, 0].values)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}\")\n",
    "\n",
    "        # Learning rate decay\n",
    "        learning_rate *= 0.95\n",
    "\n",
    "    return train_losses, train_accuracies, val_losses, val_accuracies, W0, b0, W1, b1, W2, b2\n",
    "\n",
    "\n",
    "# Usage\n",
    "df = pd.read_csv('data/train.csv')\n",
    "train_df = df.sample(frac=0.8, random_state=42)\n",
    "val_df = df.drop(train_df.index)\n",
    "\n",
    "train_losses, train_accuracies, val_losses, val_accuracies, W0, b0, W1, b1, W2, b2 = train_model(train_df, val_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424d066a-3b7c-4dd4-a50a-b3da496c3144",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X: NDArray[np.float64], W0: NDArray[np.float64], b0: NDArray[np.float64], W1: NDArray[np.float64], b1: NDArray[np.float64], W2: NDArray[np.float64], b2: NDArray[np.float64]) -> int:\n",
    "    output, _, _, _, _, _ = forward_pass(X.reshape(1, -1), W0, b0, W1, b1, W2, b2)\n",
    "    return np.argmax(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7d6cf0-7f70-4db0-9f0a-47791a6efd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions_grid(val_df: pd.DataFrame, W0: NDArray[np.float64], b0: NDArray[np.float64], W1: NDArray[np.float64], b1: NDArray[np.float64], W2: NDArray[np.float64], b2: NDArray[np.float64], num_grids: int = 1):\n",
    "    for grid in range(num_grids):\n",
    "        # Select 9 random samples from the entire dataframe\n",
    "        sample_df = val_df.sample(9)\n",
    "        \n",
    "        # Create a 3x3 subplot\n",
    "        fig, axes = plt.subplots(3, 3, figsize=(12, 12))\n",
    "        \n",
    "        for i, ax in enumerate(axes.flat):\n",
    "            # Extract the pixel values and reshape into a 28x28 array\n",
    "            pixel_values = sample_df.iloc[i, 1:].values.astype(np.float64) / 255.0\n",
    "            true_label = sample_df.iloc[i, 0]\n",
    "            \n",
    "            # Predict the digit\n",
    "            predicted_digit = predict(pixel_values, W0, b0, W1, b1, W2, b2)\n",
    "            \n",
    "            # Plot the image on the current subplot\n",
    "            ax.imshow(pixel_values.reshape(28, 28), cmap='gray')\n",
    "            ax.set_title(f\"True: {true_label}, Pred: {predicted_digit}\")\n",
    "            ax.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172b0ea4-e758-4f0a-bd27-e858eb4d383e",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_predictions_grid(val_df, W0, b0, W1, b1, W2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980418e3-62ca-470b-8477-cae1d369598b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_incorrect_predictions(val_df: pd.DataFrame, W0: NDArray[np.float64], b0: NDArray[np.float64], W1: NDArray[np.float64], b1: NDArray[np.float64], W2: NDArray[np.float64], b2: NDArray[np.float64]) -> List[Tuple[int, int, int]]:\n",
    "    incorrect_predictions = []\n",
    "    \n",
    "    for index, row in val_df.iterrows():\n",
    "        true_label = row.iloc[0]\n",
    "        pixel_values = row.iloc[1:].values.astype(np.float64) / 255.0\n",
    "        predicted_digit = predict(pixel_values, W0, b0, W1, b1, W2, b2)\n",
    "        \n",
    "        if predicted_digit != true_label:\n",
    "            incorrect_predictions.append((index, int(true_label), int(predicted_digit)))\n",
    "    \n",
    "    return incorrect_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8ba54e-6171-4756-aa3e-6bdaa824d049",
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_preds = get_incorrect_predictions(val_df, W0, b0, W1, b1, W2, b2)\n",
    "\n",
    "# Print summary of incorrect predictions\n",
    "print(f\"Total incorrect predictions: {len(incorrect_preds)}\")\n",
    "print(f\"Accuracy: {1 - len(incorrect_preds) / len(val_df):.4f}\")\n",
    "\n",
    "# Print first few incorrect predictions\n",
    "print(\"\\nSample of incorrect predictions (index, true label, predicted label):\")\n",
    "for pred in incorrect_preds[:10]:\n",
    "    print(pred)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (talk0)",
   "language": "python",
   "name": "talk0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
